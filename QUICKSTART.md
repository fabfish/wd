# Quick Start Guide

## ğŸš€ Run All Experiments (One Command)

For GPUs 0-7, simply run:

```bash
./run_all_experiments.sh
```

Or with Python:

```bash
python run_all_experiments.py
```

**That's it!** The script will:
- âœ… Check your environment
- âœ… Run all 3 experiment sets (83 runs total)
- âœ… Use all 8 GPUs efficiently
- âœ… Generate plots automatically
- âœ… Save results to `outputs/results/results.csv`
- âœ… Print summary with best results

**Estimated time: ~1.5-2 hours on 8Ã—A100**

---

## âš¡ Parallel Mode (Faster!)

Run all experiments simultaneously:

```bash
./run_all_experiments.sh --parallel
```

**Estimated time: ~45-60 minutes on 8Ã—A100**

GPU allocation:
- Experiment 1 (24 runs) â†’ GPUs 0-2
- Experiment 2 (35 runs) â†’ GPUs 3-5  
- Experiment 3 (24 runs) â†’ GPUs 6-7

---

## ğŸ’¾ Save Model Checkpoints

```bash
./run_all_experiments.sh --save-checkpoints
```

Checkpoints will be saved to `outputs/checkpoints/`

---

## ğŸ“Š Output Files

After running, you'll find:

```
outputs/
â”œâ”€â”€ logs/              # Detailed logs
â”œâ”€â”€ results/           
â”‚   â””â”€â”€ results.csv    # All experiment results
â”œâ”€â”€ checkpoints/       # Model weights (if --save-checkpoints)
â””â”€â”€ plots/             # Visualizations
    â”œâ”€â”€ exp1_lr_ordering.png
    â”œâ”€â”€ exp2_eta_lambda_heatmap.png
    â””â”€â”€ exp3_batch_size_scaling.png
```

---

## ğŸ” View Results

```bash
# View plots
eog outputs/plots/*.png           # Linux
open outputs/plots/*.png          # macOS

# Analyze results
python plot_results.py --stats

# Check logs
cat outputs/logs/exp*.log
```

---

## âš™ï¸ Advanced Options

```bash
# Custom epochs
./run_all_experiments.sh --epochs 200

# Different GPUs
./run_all_experiments.sh --gpus 0-3

# All options
./run_all_experiments.sh --help
```

---

## ğŸ§ª Test Your Setup

Before running experiments, test your environment:

```bash
python test_multi_gpu.py
```

This checks:
- GPU availability
- Python packages
- Multi-GPU scheduler

---

## ğŸ› Troubleshooting

**No GPUs detected?**
```bash
nvidia-smi  # Check GPU status
python -c "import torch; print(torch.cuda.device_count())"
```

**Out of memory?**
- Reduce batch size in the experiment configurations
- Use fewer GPUs: `--gpus 0-3`

**Script won't run?**
```bash
chmod +x run_all_experiments.sh  # Make executable
```

---

## ğŸ“š Full Documentation

See [README.md](README.md) for complete documentation.

---

## ğŸ’¡ Tips

1. **Monitor Progress**: Open another terminal and run `watch -n 1 nvidia-smi`
2. **Background Execution**: Use `screen` or `tmux` for long runs
3. **Resume Failed Runs**: Results are appended, just re-run the script
4. **Save Disk Space**: Skip checkpoints unless you need them

---

Happy Experimenting! ğŸ‰
